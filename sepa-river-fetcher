#!/usr/bin/env python
from bs4 import BeautifulSoup
from urllib2 import urlopen
from datetime import datetime

URL = "http://www.sepa.org.uk/water/river_levels/river_level_data.aspx?sd=t&lc=234217"

def get_page(url):
    return urlopen(url).read()

def get_csv_link(page):
    soup = BeautifulSoup(page)
    csv = None
    for link in soup.find_all('a'):
        href = link.get("href")
        if("csv" in href):
             return href
    return None

def process_csv(CSV)
    data = CSV.split("\r\n")
    for line in data:
        s = line.split(",")
        if len(s)  == 2: #Make sure it contains the right amount of data
            depth = s[1]
            time = datetime.strptime(s[0], "%d/%m/%Y %H:%M")
            db_insert(time, depth)

def connet_db():
    pass

def disconnect_db():
    pass

def db_insert(time, value):
    pass


if __name__ == "__main__":
    PAGE = get_page(URL)
    CSV_LINK = get_csv_link(PAGE)
    if CSV_LINK is not None:
        CSV = get_page(CSV_LINK)
        if CSV is not None:
            process_csv(CSV)
